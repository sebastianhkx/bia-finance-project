{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "3"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 1. Searching for gold inside HTML files\n",
    "<p>It used to take days for financial news to spread via radio, newspapers, and word of mouth. Now, in the age of the internet, it takes seconds. Did you know news articles are <em>automatically</em> being generated from figures and earnings call streams? Hedge funds and independent traders are using data science to process this wealth of information in the quest for profit.</p>\n",
    "<p>In this notebook, we will generate investing insight by applying <a href=\"https://en.wikipedia.org/wiki/Sentiment_analysis\">sentiment analysis</a> on financial news headlines from <a href=\"https://finviz.com\">FINVIZ.com</a>. Using this <a href=\"https://en.wikipedia.org/wiki/Natural_language_processing\">natural language processing</a> technique, we can understand the emotion behind the headlines and predict whether the market <em>feels</em> good or bad about a stock. It would then be possible to make educated guesses on how certain stocks will perform and trade accordingly. (And hopefully, make money!)</p>\n",
    "<p><img src=\"https://assets.datacamp.com/production/project_611/img/fb_headlines.png\" alt=\"Facebook headlines from FINVIZ.com\"></p>\n",
    "<p>Why headlines? And why from FINVIZ?</p>\n",
    "<ol>\n",
    "<li>Headlines, which have similar length, are easier to parse and group than full articles, which vary in length.</li>\n",
    "<li>FINVIZ has a list of trusted websites, and headlines from these sites tend to be more consistent in their jargon than those from independent bloggers. Consistent textual patterns will improve the sentiment analysis.</li>\n",
    "</ol>\n",
    "<p>As <a href=\"https://en.wikipedia.org/wiki/Web_scraping\">web scraping</a> requires data science ethics (sending a lot of traffic to a FINVIZ's servers isn't very nice), the HTML files for Facebook and Tesla at various points in time have been downloaded. Let's import these files into memory.</p>\n",
    "<p><strong>Disclaimer: Investing in the stock market involves risk and can lead to monetary loss. The content in this notebook is not to be taken as financial advice.</strong> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "scrolled": true,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebh/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/sebh/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6cec2b5072e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtable_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Read the contents of the file into 'html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Find 'news-table' in the Soup and load it into 'html_table'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mhtml_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'news-table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m        \u001b[0;31m# It's a file-type object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mmarkup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         elif len(markup) <= 256 and (\n\u001b[1;32m    193\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34mb'<'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 3131: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "html_tables = {}\n",
    "\n",
    "# For every table in the datasets folder...\n",
    "for table_name in os.listdir('datasets'):\n",
    "    #this is the path to the file. Don't touch!\n",
    "    table_path = f'datasets/{table_name}'\n",
    "    # Open as a python file in read-only mode\n",
    "    table_file = open(table_path,'r')\n",
    "    # Read the contents of the file into 'html'\n",
    "    html = BeautifulSoup(table_file)\n",
    "    # Find 'news-table' in the Soup and load it into 'html_table'\n",
    "    html_table = html.find(id='news-table')\n",
    "    # Add the table to our dictionary\n",
    "    html_tables[table_name] = html_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dc": {
     "key": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fb_22sep.html': <table border=\"0\" cellpadding=\"1\" cellspacing=\"0\" class=\"fullview-news-outer\" id=\"news-table\" width=\"100%\">\n",
      "<tr><td align=\"right\" style=\"white-space:nowrap\" width=\"130\">Sep-22-18 11:08AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.cnbc.com/2018/09/22/bret-taylor-salesforce-ex-google-facebook-profile.html?__source=yahoo%7Cfinance%7Cheadline%7Cstory%7C&amp;par=yahoo&amp;yptr=yahoo\" target=\"_blank\">How former Facebook and Google engineer Bret Taylor earned Marc Benioff's trust at Salesforce</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">12:02AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/draft-order-trump-crack-down-040227816.html\" target=\"_blank\">White House Drafts Order To Look Into Google, Facebook Practices</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" style=\"white-space:nowrap\" width=\"130\">Sep-21-18 06:21PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-withdraws-direct-promotion-political-222110885.html\" target=\"_blank\">Facebook Withdraws Direct Promotion of Political Campaigns</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:18PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/video/facebooks-plan-pull-back-campaign-221804332.html\" target=\"_blank\">Facebook's Plan to Pull Back Campaign Support to Trump in 2020</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg Video</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:17PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bloomberg.com/news/videos/2018-09-21/facebook-s-plan-to-pull-back-campaign-support-to-trump-in-2020-video?utm_source=yahoo&amp;utm_medium=bd&amp;utm_campaign=headline&amp;cmpId=yhoo.headline&amp;yptr=yahoo\" target=\"_blank\">Facebook's Plan to Pull Back Campaign Support to Trump in 2020</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:10PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/video/does-f-n-g-still-221000761.html\" target=\"_blank\">Does F.A.N.G. still stand? 8 trades</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC Videos</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">05:28PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/video/stocks-hit-time-highs-f-212800897.html\" target=\"_blank\">As stocks hit all-time highs, the F.A.N.G. trade is left ...</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC Videos</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">05:21PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.marketwatch.com/story/its-time-for-companies-to-end-the-obsession-with-millennials-and-hire-older-workers-with-skills-and-expertise-2018-09-21?siteid=yhoof2&amp;yptr=yahoo\" target=\"_blank\">Its time for companies to end the obsession with millennials and hire older workers with skills and expertise</a> <span style=\"color:#aa6dc0;font-size:9px\">MarketWatch</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:04PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/earnings-calendar-week-dec-11-192003013.html\" target=\"_blank\">Earnings Reports for the Week of Sept. 24-28 (KBH, NKE, RAD)</a> <span style=\"color:#aa6dc0;font-size:9px\">Kiplinger</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:03PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.marketwatch.com/story/dow-marks-2nd-all-time-high-in-a-row-but-tech-stocks-weigh-on-broader-market-2018-09-21?siteid=yhoof2&amp;yptr=yahoo\" target=\"_blank\">Dow marks 2nd all-time high in a row but tech stocks weigh on broader market</a> <span style=\"color:#aa6dc0;font-size:9px\">MarketWatch</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:36PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-could-unveil-video-chatting-193600556.html\" target=\"_blank\">Facebook Could Unveil Its Video-Chatting Device Next Week</a> <span style=\"color:#aa6dc0;font-size:9px\">Motley Fool</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:50PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/video/facebook-rolls-dating-unique-spin-175000677.html\" target=\"_blank\">Facebook Rolls Out New Dating Service With Unique Spin</a> <span style=\"color:#aa6dc0;font-size:9px\">GoBankingRates</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">12:33PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"http://realmoney.thestreet.com/articles/09/21/2018/facebook-prices-could-trade-sideways-here?puc=yahoo&amp;cm_ven=YAHOO&amp;yptr=yahoo\" target=\"_blank\">Facebook Prices Could Trade Sideways From Here</a> <span style=\"color:#aa6dc0;font-size:9px\">TheStreet.com</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">11:45AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/lots-alphabet-stock-long-run-154539937.html\" target=\"_blank\">Theres Lots to Like About Alphabet Stock in the Long Run</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">11:41AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/finally-call-snap-stock-lost-154100860.html\" target=\"_blank\">Can We Finally Call Snap Stock a Lost Cause?</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">11:15AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/pawar-law-group-announces-securities-151500537.html\" target=\"_blank\">Pawar Law Group Announces a Securities Class Action Lawsuit Against Facebook, Inc. - FB</a> <span style=\"color:#aa6dc0;font-size:9px\">ACCESSWIRE</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:31AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/investors-avoid-alphabet-until-starts-143135009.html\" target=\"_blank\">Investors Should Avoid Alphabet Until It Starts Doing One Thing</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:00AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/amazon-becoming-third-largest-internet-140000167.html\" target=\"_blank\">Amazon Is Becoming the Third Largest Internet Ad Platform in the U.S.</a> <span style=\"color:#aa6dc0;font-size:9px\">Motley Fool</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:53AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/alphabet-facebook-netflix-destroy-stock-105300942.html\" target=\"_blank\">Alphabet, Facebook and Netflix are about to destroy the stock market's biggest dividend trade</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:51AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/video/major-p-tech-sector-organization-105100689.html\" target=\"_blank\">Major S&amp;P tech sector re-organization to take effect Mond...</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC Videos</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:01AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/aclu-pushes-facebook-little-further-100152529.html\" target=\"_blank\">ACLU Pushes Facebook a Little Further Down the Road Toward Regulation</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:46AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://uk.finance.yahoo.com/news/facebook-launched-dating-app-many-054600371.html\" target=\"_blank\">Facebook launches its new dating app, but how many people will really want to use it?</a> <span style=\"color:#aa6dc0;font-size:9px\">The Telegraph</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:36AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-drop-support-political-campaigns-003646418.html\" target=\"_blank\">Facebook to drop on-site support for political campaigns</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" style=\"white-space:nowrap\" width=\"130\">Sep-20-18 11:38PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/shopify-stock-could-way-making-033824932.html\" target=\"_blank\">Shopify Stock Could Be on Its Way to Making New Highs</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:30PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bizjournals.com/sanjose/news/2018/09/20/facebook-stretches-southward-signing-2018-s.html?ana=yahoo&amp;yptr=yahoo\" target=\"_blank\">Facebook stretches southward, signing 2018s largest Silicon Valley lease</a> <span style=\"color:#aa6dc0;font-size:9px\">American City Business Journals</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:30PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bizjournals.com/sanjose/news/2018/09/20/developer-wasted-no-time-hooking-fast.html?ana=yahoo&amp;yptr=yahoo\" target=\"_blank\">Developer wasted no time hooking fast-growing Facebook in the tech titans hometown</a> <span style=\"color:#aa6dc0;font-size:9px\">American City Business Journals</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">09:57PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-drop-support-political-campaigns-003045101.html\" target=\"_blank\">Facebook to drop on-site support for political campaigns</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:48PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.wsj.com/articles/eu-demands-facebook-update-misleading-fine-print-1537438609?ru=yahoo?mod=yahoo_itp&amp;yptr=yahoo\" target=\"_blank\">[$$] EU Demands Facebook Update Misleading Fine Print</a> <span style=\"color:#aa6dc0;font-size:9px\">The Wall Street Journal</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:27PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-less-direct-support-trump-222737178.html\" target=\"_blank\">Facebook to Give Less Direct Support to Trump in 2020 Campaign</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">05:03PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.cnbc.com/2018/09/20/theres-will-soon-be-a-new-way-to-play-fang.html?__source=yahoo%7Cfinance%7Cheadline%7Cstory%7C&amp;par=yahoo&amp;yptr=yahoo\" target=\"_blank\">There will soon be a new way to play FANG stocks</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:15PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bizjournals.com/portland/news/2018/09/20/facebook-adds-two-more-buildings-to-prineville.html?ana=yahoo&amp;yptr=yahoo\" target=\"_blank\">Facebook adds two more buildings to Prineville data centers</a> <span style=\"color:#aa6dc0;font-size:9px\">American City Business Journals</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:05PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"http://realmoney.thestreet.com/articles/09/20/2018/live-markets-blog?puc=yahoo&amp;cm_ven=YAHOO&amp;yptr=yahoo\" target=\"_blank\">Closing Bell: LIVE MARKETS BLOG</a> <span style=\"color:#aa6dc0;font-size:9px\">TheStreet.com</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:57PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/search-internet-journalism-business-models-195756479.html\" target=\"_blank\">Has the Search for Internet Journalism Business Models Come to an End?</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:49PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.marketwatch.com/story/facebook-begins-rollout-of-dating-product-starting-in-colombia-2018-09-20?siteid=yhoof2&amp;yptr=yahoo\" target=\"_blank\">Facebook begins rollout of dating product, starting in Colombia</a> <span style=\"color:#aa6dc0;font-size:9px\">MarketWatch</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:56PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/buy-roku-stock-huge-175-175601172.html\" target=\"_blank\">Should You Buy Roku Stock After Its Huge 175% Run-up?</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:55PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-expands-fake-election-news-175549200.html\" target=\"_blank\">Facebook expands fake election news fight, but falsehoods still rampant</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:43PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.marketwatch.com/story/heres-a-clear-case-for-owning-dividend-stocks-instead-of-bonds-2018-09-19?siteid=yhoof2&amp;yptr=yahoo\" target=\"_blank\">Heres a clear case for owning dividend stocks instead of bonds</a> <span style=\"color:#aa6dc0;font-size:9px\">MarketWatch</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:31PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/why-time-unload-facebook-stock-173126305.html\" target=\"_blank\">Why Its Time to Unload Facebook Stock</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:08PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/britain-preparing-set-internet-regulator-165448196.html\" target=\"_blank\">Britain preparing to set up internet regulator: Buzzfeed</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">12:56PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/don-t-buy-dip-darker-165632938.html\" target=\"_blank\">Dont Buy the Dip, There Are Darker Days Ahead for Twitter Stock</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">12:14PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-stock-strong-buy-unless-161437028.html\" target=\"_blank\">Facebook Stock Is a Strong Buy, Unless This Happens</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:58AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/ahead-index-shuffle-investors-flock-145802371.html\" target=\"_blank\">Ahead of Index Shuffle, Investors Flock to Communication Sector ETF</a> <span style=\"color:#aa6dc0;font-size:9px\">ETF Trends</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:35AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/investors-stop-unfriending-facebook-stock-143532196.html\" target=\"_blank\">Investors Should Stop Unfriending Facebook Stock</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:24AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.cnbc.com/2018/09/20/facebook-reportedly-testing-new-dating-feature-with-fail-safe-options.html?__source=yahoo%7Cfinance%7Cheadline%7Cstory%7C&amp;par=yahoo&amp;yptr=yahoo\" target=\"_blank\">Facebook said to test new dating feature in Colombia with safeguards to prevent stalking</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">09:56AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/company-news-sep-20-2018-135601069.html\" target=\"_blank\">Company News For Sep 20, 2018</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">09:12AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.wsj.com/articles/stocks-to-watch-tilray-jpmorgan-chase-red-hat-1537441409?mod=yahoo_hs&amp;yptr=yahoo\" target=\"_blank\">[$$] Stocks to Watch: Comcast, Tilray, Facebook, Amazon.com, Bank of America, JPMorgan Chase, Red Hat, Darden Restaurants, Herman Miller</a> <span style=\"color:#aa6dc0;font-size:9px\">The Wall Street Journal</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:34AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/zacks-earnings-trends-highlights-apple-113411865.html\" target=\"_blank\">Zacks Earnings Trends Highlights: Apple, Alphabet and Facebook</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:30AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/google-facebook-lead-digital-march-113000277.html\" target=\"_blank\">Google, Facebook Lead Digitals March to Half of U.S. Ad Market</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:22AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://uk.finance.yahoo.com/news/eu-warns-facebook-fines-apos-112235352.html\" target=\"_blank\">EU warns Facebook of fines for 'misleading' terms of service</a> <span style=\"color:#aa6dc0;font-size:9px\">The Telegraph</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:34AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.wsj.com/articles/eu-demands-facebook-update-misleading-fine-print-1537438609?mod=yahoo_hs&amp;yptr=yahoo\" target=\"_blank\">[$$] EU Demands Facebook Update 'Misleading' Fine Print</a> <span style=\"color:#aa6dc0;font-size:9px\">The Wall Street Journal</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:24AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/eu-says-facebook-must-comply-081924943.html\" target=\"_blank\">Facebook and Twitter must comply with EU consumer rules or face sanctions</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:22AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/eu-says-facebook-must-comply-082242350.html\" target=\"_blank\">EU says Facebook must comply with EU consumer rules by end-2018 or face sanctions</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:00AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/silicon-valley-publishers-fight-eu-050000121.html\" target=\"_blank\">Silicon Valley and Publishers Fight on After EU Copyright Vote</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" style=\"white-space:nowrap\" width=\"130\">Sep-19-18 09:00PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/emarketer-amazon-just-became-third-010000226.html\" target=\"_blank\">eMarketer: Amazon Just Became the Third-Largest U.S. Digital Ad Platform</a> <span style=\"color:#aa6dc0;font-size:9px\">Motley Fool</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">08:38PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-expands-fake-election-news-003809635.html\" target=\"_blank\">Facebook expands fake election news fight, but falsehoods still rampant</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">08:08PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-apple-wants-create-trust-000800446.html\" target=\"_blank\">Like Facebook, Apple Wants to Create a &amp;quot;Trust Score&amp;quot; About You</a> <span style=\"color:#aa6dc0;font-size:9px\">Motley Fool</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:03PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-expands-fake-election-news-230357598.html\" target=\"_blank\">Facebook expands fake election news fight, but falsehoods still rampant</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:35PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/why-did-facebook-fb-stock-223510441.html\" target=\"_blank\">Why Did Facebook (FB) Stock Climb Wednesday?</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">05:54PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bizjournals.com/sanfrancisco/news/2018/09/19/macys-facebook-vr-retail.html?ana=yahoo&amp;yptr=yahoo\" target=\"_blank\">Macy's partners with Facebook to bring virtual reality into its stores</a> <span style=\"color:#aa6dc0;font-size:9px\">American City Business Journals</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">05:45PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-fb-outpaces-stock-market-214509221.html\" target=\"_blank\">Facebook (FB) Outpaces Stock Market Gains: What You Should Know</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:19PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/why-p-500-rally-big-201937662.html\" target=\"_blank\">This Is Why the S&amp;P 500 Will Rally Big Into the End of 2018</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:04PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"http://realmoney.thestreet.com/articles/09/19/2018/live-markets-blog?puc=yahoo&amp;cm_ven=YAHOO&amp;yptr=yahoo\" target=\"_blank\">Closing Bell: LIVE MARKETS BLOG</a> <span style=\"color:#aa6dc0;font-size:9px\">TheStreet.com</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">04:02PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/5-top-stock-trades-thursday-200226369.html\" target=\"_blank\">5 Top Stock Trades for Thursday  Trading FANG Stocks and Tilray</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:53PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bizjournals.com/memphis/news/2018/09/19/facebook-gender-bias-lawsuit.html?ana=yahoo&amp;yptr=yahoo\" target=\"_blank\">Lawsuit says Facebook lets employers exclude women in recruiting campaigns</a> <span style=\"color:#aa6dc0;font-size:9px\">American City Business Journals</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:36PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/concern-tech-etfs-despite-qqq-193642006.html\" target=\"_blank\">A Concern for Tech ETFs Despite QQQ Up 18% YTD?</a> <span style=\"color:#aa6dc0;font-size:9px\">ETF Trends</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:34PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/google-facebook-fear-amazon-apos-193407521.html\" target=\"_blank\">Should Google &amp; Facebook Fear Amazon's Growing Ad Business?</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:21PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.marketwatch.com/story/not-just-tech-the-stock-market-rally-is-broader-than-its-given-credit-for-2018-09-19?siteid=yhoof2&amp;yptr=yahoo\" target=\"_blank\">Not just tech: The stock-market rally is broader than its given credit for</a> <span style=\"color:#aa6dc0;font-size:9px\">MarketWatch</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:50PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-yet-comply-eu-consumer-183705590.html\" target=\"_blank\">Facebook yet to comply with EU consumer rules, Airbnb in line: EU sources</a> <span style=\"color:#aa6dc0;font-size:9px\">Reuters</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:01PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://uk.finance.yahoo.com/news/facebook-accused-discriminating-against-women-180110951.html\" target=\"_blank\">Facebook accused of discriminating against women with male-targeted job adverts</a> <span style=\"color:#aa6dc0;font-size:9px\">The Independent</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:56AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.investopedia.com/news/amazon-gains-ad-market-share-google-facebook/?partner=YahooSA&amp;yptr=yahoo\" target=\"_blank\">Amazon Gains Ad Market Share From Google, Facebook</a> <span style=\"color:#aa6dc0;font-size:9px\">Investopedia</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:45AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.thestreet.com/investing/amazon-ad-business-makes-strides-as-it-is-now-third-in-market-share-14717373?puc=yahoo&amp;cm_ven=YAHOO&amp;yptr=yahoo\" target=\"_blank\">Amazon's Ad Business Moves Up to Third in U.S. Market Share</a> <span style=\"color:#aa6dc0;font-size:9px\">TheStreet.com</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:40AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/alexa-devices-power-amazon-stock-144000306.html\" target=\"_blank\">New Alexa Devices Can Power Amazon Stock  and Hurt Rivals</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:24AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bizjournals.com/sanjose/news/2018/09/19/facebook-ar-glasses-chip-hiring-oculus.html?ana=yahoo&amp;yptr=yahoo\" target=\"_blank\">Job postings suggest Facebook could be developing an in-house AR chip</a> <span style=\"color:#aa6dc0;font-size:9px\">American City Business Journals</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:17AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.marketwatch.com/story/amazon-to-become-the-third-largest-digital-ad-platform-in-the-us-2018-09-19?siteid=yhoof2&amp;yptr=yahoo\" target=\"_blank\">Amazon to become the third largest digital ad platform in the U.S.</a> <span style=\"color:#aa6dc0;font-size:9px\">MarketWatch</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">10:14AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.cnbc.com/2018/09/19/prophet-brand-relevance-index-most-relevant-brands-to-consumers.html?__source=yahoo%7Cfinance%7Cheadline%7Cstory%7C&amp;par=yahoo&amp;yptr=yahoo\" target=\"_blank\">These are the 10 most relevant brands to consumersFacebook, Twitter, Snapchat didn't make the list</a> <span style=\"color:#aa6dc0;font-size:9px\">CNBC</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">09:19AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/final-deadline-alert-brower-piven-131900682.html\" target=\"_blank\">FINAL DEADLINE ALERT: Brower Piven Reminds Shareholders Of Approaching Deadline In Class Action Lawsuit And Encourages Those Who Have Losses In Excess Of $100,000 From Investment In Facebook, Inc. (Nasdaq: FB) To Contact The Firm</a> <span style=\"color:#aa6dc0;font-size:9px\">GlobeNewswire</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:40AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://uk.finance.yahoo.com/news/amazon-makes-headway-breaking-facebook-114010857.html\" target=\"_blank\">Amazon makes headway in breaking up Facebook and Google's digital ad duopoly</a> <span style=\"color:#aa6dc0;font-size:9px\">The Telegraph</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:00AM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.bloomberg.com/news/articles/2018-09-19/amazon-increases-ad-market-share-at-expense-of-google-facebook?utm_source=yahoo&amp;utm_medium=bd&amp;utm_campaign=headline&amp;cmpId=yhoo.headline&amp;yptr=yahoo\" target=\"_blank\">Amazon Increases Ad Market Share at Expense of Google, Facebook</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" style=\"white-space:nowrap\" width=\"130\">Sep-18-18 08:20PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.wsj.com/articles/facebook-sought-access-to-financial-firms-customer-data-1537263000?ru=yahoo?mod=yahoo_itp&amp;yptr=yahoo\" target=\"_blank\">[$$] Facebook and Financial Firms Tussled for Years Over Access to User Data</a> <span style=\"color:#aa6dc0;font-size:9px\">The Wall Street Journal</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">08:20PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.wsj.com/articles/bertelsmann-to-merge-unit-that-moderates-for-facebook-with-a-competitor-1537273357?ru=yahoo?mod=yahoo_itp&amp;yptr=yahoo\" target=\"_blank\">[$$] Bertelsmann to Merge Unit That Moderates for Facebook With a Competitor</a> <span style=\"color:#aa6dc0;font-size:9px\">The Wall Street Journal</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">07:12PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/oregon-using-facebook-remind-inactive-voters-register-212642624--politics.html\" target=\"_blank\">Oregon using Facebook to remind inactive voters to register</a> <span style=\"color:#aa6dc0;font-size:9px\">Associated Press</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:56PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/law-offices-howard-g-smith-225600947.html\" target=\"_blank\">The Law Offices of Howard G. Smith Reminds Investors of Looming Deadline in the Class Action Lawsuit Against Facebook, Inc. (FB)</a> <span style=\"color:#aa6dc0;font-size:9px\">Business Wire</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:47PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.yahoo.com/tech/oregon-using-facebook-remind-inactive-voters-register-212642624--politics.html\" target=\"_blank\">Oregon using Facebook to remind inactive voters to register</a> <span style=\"color:#aa6dc0;font-size:9px\">Associated Press</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">06:35PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/law-offices-howard-g-smith-223510606.html\" target=\"_blank\">The Law Offices of Howard G. Smith Reminds Investors of Looming Deadline in the Class Action Lawsuit Against Facebook, Inc. (FB)</a> <span style=\"color:#aa6dc0;font-size:9px\">GlobeNewswire</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">05:43PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.yahoo.com/news/facebook-accused-gender-bias-214331862.html\" target=\"_blank\">Facebook accused of gender bias</a> <span style=\"color:#aa6dc0;font-size:9px\">CBS News Videos</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:42PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.wired.com/story/qanon-conspiracy-facebook-meme-ai?yptr=yahoo\" target=\"_blank\">QAnon Is Trying to Trick Facebooks Meme-Reading AI</a> <span style=\"color:#aa6dc0;font-size:9px\">Wired</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:14PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://uk.finance.yahoo.com/news/facebook-accused-discriminating-against-women-191404769.html\" target=\"_blank\">Facebook accused of discriminating against women with targeted job adverts</a> <span style=\"color:#aa6dc0;font-size:9px\">The Telegraph</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:11PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/apos-another-way-facebook-monetize-191100197.html\" target=\"_blank\">Here's Another Way Facebook Can Monetize Instagram</a> <span style=\"color:#aa6dc0;font-size:9px\">Motley Fool</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">03:07PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/decline-facebook-stock-created-good-190750272.html\" target=\"_blank\">The Decline of Facebook Stock Has Created a Good Buying Opportunity</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:38PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/aclu-says-facebook-allows-gender-134317035.html\" target=\"_blank\">ACLU: Facebook allows gender-biased job ads on its platform</a> <span style=\"color:#aa6dc0;font-size:9px\">Associated Press</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:36PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-jpmorgans-most-controversial-company-183655877.html\" target=\"_blank\">Facebook Is JPMorgan's Most Controversial Company in Portfolio</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:36PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.yahoo.com/tech/aclu-says-facebook-allows-gender-134317035.html\" target=\"_blank\">ACLU: Facebook allows gender-biased job ads on its platform</a> <span style=\"color:#aa6dc0;font-size:9px\">Associated Press</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:05PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/only-one-media-stocks-long-180523050.html\" target=\"_blank\">Only One of These Media Stocks Is a Long-Term Buy on NFL Prospects</a> <span style=\"color:#aa6dc0;font-size:9px\">InvestorPlace</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">02:00PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://www.investopedia.com/news/aclu-files-discrimination-complaint-against-facebook-targeted-job-ads/?partner=YahooSA&amp;yptr=yahoo\" target=\"_blank\">ACLU Files Discrimination Complaint Against Facebook for Targeted Job Ads</a> <span style=\"color:#aa6dc0;font-size:9px\">Investopedia</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:54PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/investors-pour-money-etf-ahead-175407162.html\" target=\"_blank\">Investors Pour Money Into This ETF Ahead of Index Reorganization</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:40PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/tesla-china-facebook-macy-apos-174005478.html\" target=\"_blank\">The Tesla of China &amp; the Facebook-Macy's Connection | Free Lunch</a> <span style=\"color:#aa6dc0;font-size:9px\">Zacks</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:24PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-cant-settle-one-ad-172424245.html\" target=\"_blank\">Facebook Can't Settle One Ad Bias Claim, Gets Hit With Another</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:24PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/facebook-cant-settle-one-ad-172424960.html\" target=\"_blank\">Facebook Can't Settle an Ad Bias Claim, Draws New Complaint</a> <span style=\"color:#aa6dc0;font-size:9px\">Bloomberg</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">01:00PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/news/class-action-tsla-rmti-fb-170000250.html\" target=\"_blank\">CLASS ACTION UPDATE for TSLA, RMTI and FB: Levi &amp; Korsinsky, LLP Reminds Investors of Class Actions on Behalf of Shareholders</a> <span style=\"color:#aa6dc0;font-size:9px\">GlobeNewswire</span></td></tr>\n",
      "<tr><td align=\"right\" width=\"130\">12:50PM  </td><td align=\"left\"><a class=\"tab-link-news\" href=\"https://finance.yahoo.com/video/aclu-labor-union-allege-facebooks-165002685.html\" target=\"_blank\">Facebook Is Facing a Legal Battle with ACLU &amp; CWA</a> <span style=\"color:#aa6dc0;font-size:9px\">Meredith Videos</span></td></tr>\n",
      "</table>}\n"
     ]
    }
   ],
   "source": [
    "print(html_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "10"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 2. What is inside those files anyway?\n",
    "<p>We've grabbed the table that contains the headlines from each stock's HTML file, but before we start parsing those tables further, we need to understand how the data in that table is structured. We have a few options for this:</p>\n",
    "<ul>\n",
    "<li>Open the HTML file with a text editor (preferably one with syntax highlighting, like <a href=\"http://www.sublimetext.com/\">Sublime Text</a>) and explore it there</li>\n",
    "<li>Use your browser's <a href=\"https://addons.mozilla.org/en-US/firefox/addon/web-developer/\">webdev toolkit</a> to explore the HTML</li>\n",
    "<li>Explore the headlines table here in this notebook!</li>\n",
    "</ul>\n",
    "<p>Let's do the third option.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "scrolled": false,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tsla_22sep.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4a4ba797f003>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read one single day of headlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtsla\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml_tables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tsla_22sep.html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get all the table rows tagged in HTML with <tr> into 'tesla_tr'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtsla_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tsla_22sep.html'"
     ]
    }
   ],
   "source": [
    "# Read one single day of headlines \n",
    "tsla = html_tables['tsla_22sep.html']\n",
    "# Get all the table rows tagged in HTML with <tr> into 'tesla_tr'\n",
    "tsla_tr = tsla.findAll('tr')\n",
    "\n",
    "# For each row...\n",
    "for i, table_row in enumerate(tsla_tr):\n",
    "    # Read the text of the element 'a' into 'link_text'\n",
    "    link_text = table_row.a.get_text()\n",
    "    # Read the text of the element 'td' into 'data_text'\n",
    "    data_text = table_row.td.get_text()\n",
    "    # Print the count\n",
    "    print(f'{i}:')\n",
    "    # Print the contents of 'link_text' and 'data_text' \n",
    "    print(link_text)\n",
    "    print(data_text)\n",
    "    # The following exits the loop after three rows to prevent spamming the notebook, do not touch\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "17"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. Extra, extra! Extract the news headlines\n",
    "<p>As we saw above, the interesting data inside each table row (<code>&lt;tr&gt;</code>) is in the text inside the <code>&lt;td&gt;</code> and <code>&lt;a&gt;</code> tags. Let's now actually parse the data for <strong>all</strong> tables in a comfortable data structure.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Hold the parsed news into a list\n",
    "parsed_news = []\n",
    "# Iterate through the news\n",
    "for file_name, news_table in html_tables.items():\n",
    "    # Iterate through all tr tags in 'news_table'\n",
    "    for x in news_table.findAll('tr'):\n",
    "        # Read the text from the tr tag into text\n",
    "        text = x.get_text() \n",
    "        # Split the text in the td tag into a list \n",
    "        date_scrape = x.td.text.split()\n",
    "#         print(date_scrape)\n",
    "        # If the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "        # If not, load 'date' as the 1st element and 'time' as the second\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "        # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
    "        ticker = file_name.split('_')[0]\n",
    "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
    "        parsed_news.append([ticker, date, time, x.a.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pprint.pprint(parsed_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "24"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. Make NLTK think like a financial journalist\n",
    "<p>Sentiment analysis is very sensitive to context. As an example, saying <em>\"This is so addictive!\"</em> often means something positive if the context is a video game you are enjoying with your friends, but it very often means something negative when we are talking about opioids. Remember that the reason we chose headlines is so we can try to extract sentiment from financial journalists, who like most professionals, have their own lingo. Let's now make NLTK think like a financial journalist by adding some new words and sentiment values to our lexicon.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dc": {
     "key": "24"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  Searched in:\n    - '/Users/sebh/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/Users/sebh/anaconda3/nltk_data'\n    - '/Users/sebh/anaconda3/share/nltk_data'\n    - '/Users/sebh/anaconda3/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f043f5bfead2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Instantiate the sentiment intensity analyzer with the existing lexicon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# Update the lexicon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# nltk.download('stopwords')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lexicon_file)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \"\"\"\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlexicon_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexicon_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_lex_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mvader_lexicon\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('vader_lexicon')\n  \u001b[0m\n  Searched in:\n    - '/Users/sebh/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/Users/sebh/anaconda3/nltk_data'\n    - '/Users/sebh/anaconda3/share/nltk_data'\n    - '/Users/sebh/anaconda3/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# NLTK VADER for sentiment analysis\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# New words and values\n",
    "new_words = {\n",
    "    'crushes': 10,\n",
    "    'beats': 5,\n",
    "    'misses': -5,\n",
    "    'trouble': -10,\n",
    "    'falls': -100,\n",
    "}\n",
    "# Instantiate the sentiment intensity analyzer with the existing lexicon\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "# Update the lexicon\n",
    "# nltk.download('stopwords')\n",
    "vader.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "31"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. BREAKING NEWS: NLTK Crushes Sentiment Estimates\n",
    "<p>Now that we have the data and the algorithm loaded, we will get to the core of the matter: programmatically predicting sentiment out of news headlines! Luckily for us, VADER is very high level so, in this case, we will not adjust the model further<sup>*</sup> other than the lexicon additions from before.</p>\n",
    "<p><sup>*</sup>VADER \"out-of-the-box\" with some extra lexicon would likely translate into <strong>heavy losses</strong> with real money. A real sentiment analysis tool with chances of being profitable will require a very extensive and dedicated to finance news lexicon. Furthermore, it might also not be enough using a pre-packaged model like VADER.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-479f157dcd82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscored_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_news\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Iterate through the headlines and get the polarity scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnews\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_news\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert the list of dicts into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-479f157dcd82>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscored_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_news\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Iterate through the headlines and get the polarity scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnews\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_news\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Convert the list of dicts into a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vader' is not defined"
     ]
    }
   ],
   "source": [
    "# Use these column names\n",
    "columns = ['ticker', 'date', 'time', 'headline']\n",
    "# Convert the list of lists into a DataFrame\n",
    "scored_news = pd.DataFrame(parsed_news,columns=columns)\n",
    "# Iterate through the headlines and get the polarity scores\n",
    "scores = [vader.polarity_scores(news[3]) for news in parsed_news]\n",
    "# print(scores)\n",
    "# Convert the list of dicts into a DataFrame\n",
    "scores_df = pd.DataFrame(scores)\n",
    "# print(scores_df)\n",
    "# Join the DataFrames\n",
    "scored_news = scored_news.join(scores_df)\n",
    "# Convert the date column from string to datetime\n",
    "scored_news['date'] = pd.to_datetime(scored_news.date).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "38"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Plot all the sentiment in subplots\n",
    "<p>Now that we have the scores, let's start plotting the results. We will start by plotting the time series for the stocks we have.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dc": {
     "key": "38"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_news['date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-288f7192f5e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Group by date and ticker columns from scored_news and calculate the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmean_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscored_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# display(mean_c.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Unstack the column ticker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_groupby_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'numeric_only'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGroupByError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   3972\u001b[0m                             min_count=-1):\n\u001b[1;32m   3973\u001b[0m         new_items, new_blocks = self._cython_agg_blocks(\n\u001b[0;32m-> 3974\u001b[0;31m             how, alt=alt, numeric_only=numeric_only, min_count=min_count)\n\u001b[0m\u001b[1;32m   3975\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_blocks\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   4044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4046\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No numeric types to aggregate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4048\u001b[0m         \u001b[0;31m# reset the locs in the blocks to correspond to our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Group by date and ticker columns from scored_news and calculate the mean\n",
    "mean_c = scored_news.groupby(['date', 'ticker']).mean()\n",
    "# display(mean_c.head())\n",
    "# Unstack the column ticker\n",
    "mean_c = mean_c.unstack(1)\n",
    "# Get the cross-section of compound in the 'columns' axis\n",
    "mean_c = mean_c['compound']\n",
    "# Plot a bar chart with pandas\n",
    "# ... YOUR CODE FOR TASK 6 ...\n",
    "mean_c.head()\n",
    "mean_c.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "45"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 7. Weekends and duplicates\n",
    "<p>What happened to Tesla on November 22nd? Since we happen to have the headlines inside our <code>DataFrame</code>, a quick peek reveals that there are a few problems with that particular day: </p>\n",
    "<ul>\n",
    "<li>There are only 5 headlines for that day.</li>\n",
    "<li>Two headlines are verbatim the same as another but from another news outlet.</li>\n",
    "</ul>\n",
    "<p>Let's clean up the dataset a bit, but not too much! While some headlines are the same news piece from different sources, the fact that they are written differently could provide different perspectives on the same story. Plus, when one piece of news is more important, it tends to get more headlines from multiple sources. What we want to get rid of is verbatim copied headlines, as these are very likely coming from the same journalist and are just being \"forwarded\" around, so to speak.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scored_news' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-34534c43ce94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Count the number of headlines in scored_news (store as integer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_news_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscored_news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Drop duplicates based on ticker and headline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscored_news_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscored_news\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Count number of headlines after dropping duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scored_news' is not defined"
     ]
    }
   ],
   "source": [
    "# Count the number of headlines in scored_news (store as integer)\n",
    "num_news_before = len(scored_news)\n",
    "# Drop duplicates based on ticker and headline\n",
    "scored_news_clean = scored_news.drop_duplicates(subset = ['ticker','headline'])\n",
    "# Count number of headlines after dropping duplicates\n",
    "num_news_after = len(scored_news_clean)\n",
    "# Print before and after numbers to get an idea of how we did \n",
    "print(f\"Before we had {num_news_before} headlines, now we have {num_news_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "52"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 8. Sentiment on one single trading day and stock\n",
    "<p>Just to understand the possibilities of this dataset and get a better feel of the data, let's focus on one trading day and one single stock. We will make an informative plot where we will see the smallest grain possible: headline and subscores.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'the label [2019-01-04] is not in the [index]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m                     \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [2019-01-04] is not in the [index]'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8b8d9ff2d585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msingle_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fb\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Select the 3rd of January of 2019\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msingle_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'2019-01-04'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert the datetime string to just the time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msingle_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_day\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_label_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;31m# we have yielded a scalar ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m                 \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36merror\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 raise KeyError(u\"the label [{key}] is not in the [{axis}]\"\n\u001b[1;32m   1784\u001b[0m                                .format(key=key,\n\u001b[0;32m-> 1785\u001b[0;31m                                        axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'the label [2019-01-04] is not in the [index]'"
     ]
    }
   ],
   "source": [
    "# Set the index to ticker and date\n",
    "single_day = scored_news_clean.set_index(['ticker', 'date'])\n",
    "# Cross-section the fb row\n",
    "single_day = single_day.loc[\"fb\"]\n",
    "# Select the 3rd of January of 2019\n",
    "single_day = single_day.loc['2019-01-04',:]\n",
    "# Convert the datetime string to just the time\n",
    "single_day['time'] = pd.to_datetime(single_day['time']).dt.time\n",
    "# Set the index to time and \n",
    "single_day = single_day.set_index('time')\n",
    "# Sort it\n",
    "single_day = single_day.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "59"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 9. Visualize the single day\n",
    "<p>We will make a plot to visualize the positive, negative and neutral scores for a single day of trading and a single stock. This is just one of the many ways to visualize this dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"labels ['compound'] not contained in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5ea04720ca0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mCOLORS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"green\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Drop the columns that aren't useful for the plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_day\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msingle_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'headline'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Change the column names to 'negative', 'positive', and 'neutral'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplot_day\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'negative'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'positive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'neutral'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3138\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4387\u001b[0;31m                     'labels %s not contained in axis' % labels[mask])\n\u001b[0m\u001b[1;32m   4388\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"labels ['compound'] not contained in axis\""
     ]
    }
   ],
   "source": [
    "TITLE = \"Positive, negative and neutral sentiment for FB on 2019-01-03\"\n",
    "COLORS = [\"red\", \"orange\", \"green\"]\n",
    "# Drop the columns that aren't useful for the plot\n",
    "plot_day = single_day.drop(columns = ['compound', 'headline'])\n",
    "# Change the column names to 'negative', 'positive', and 'neutral'\n",
    "plot_day.columns = ['negative','positive','neutral']\n",
    "# Plot a stacked bar chart\n",
    "# ... YOUR CODE FOR TASK 9 :-) ...\n",
    "plot_day.plot.bar(stacked = True,\n",
    "                 figsize = (10, 6),\n",
    "                 title = TITLE,\n",
    "                 color = COLORS).legend(bbox_to_anchor = (1.2, 0.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
